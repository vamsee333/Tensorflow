{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow mutiple category classifier model with IRIS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sns.load_dataset(\"iris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\n",
      "8192/2194 [================================================================================================================] - 0s 0s/step\n",
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\n",
      "8192/573 [============================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 0s/step\n"
     ]
    }
   ],
   "source": [
    "## its an other approach to read the data where tensorflow converts the categorical values to numerical automatically\n",
    "\n",
    "\n",
    "train_path = tf.keras.utils.get_file(\n",
    "    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
    "test_path = tf.keras.utils.get_file(\n",
    "    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
    "\n",
    "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train\n",
    "X_test=test\n",
    "Y_train=X_train.pop(\"Species\")\n",
    "Y_test= X_test.pop(\"Species\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SepalLength\n",
      "SepalWidth\n",
      "PetalLength\n",
      "PetalWidth\n"
     ]
    }
   ],
   "source": [
    "for i in train.keys():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SepalLength\n",
      "SepalWidth\n",
      "PetalLength\n",
      "PetalWidth\n",
      "Species\n"
     ]
    }
   ],
   "source": [
    "for i in train.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create feature columns as \n",
    "\n",
    "feature_columns=[]\n",
    "\n",
    "for col in X_train.columns:\n",
    "    feature_columns.append(tf.feature_column.numeric_column(col,dtype=tf.float64))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n",
       " NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n",
       " NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None),\n",
       " NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float64, normalizer_fn=None)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create input function, use lambda concept\n",
    "\n",
    "def input_func(features, labels, training=True,batch_size=256):\n",
    "    res = tf.data.Dataset.from_tensor_slices((dict(features),labels))\n",
    "    \n",
    "     # Shuffle and repeat if you are in training mode.\n",
    "    if training:\n",
    "        res = res.shuffle(1000).repeat()\n",
    "    \n",
    "    return res.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\vamsee\\AppData\\Local\\Temp\\tmpywpck99t\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\vamsee\\\\AppData\\\\Local\\\\Temp\\\\tmpywpck99t', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "### now create an estimator\n",
    "\n",
    "model = tf.estimator.DNNClassifier(\n",
    "    ### feature columns \n",
    "    feature_columns=feature_columns,\n",
    "    \n",
    "    ## it represents the no of output classes\n",
    "    n_classes=3,\n",
    "    \n",
    "    hidden_units =[10,20,30]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\vamsee\\AppData\\Local\\Temp\\tmpywpck99t\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 1.1215439, step = 0\n",
      "INFO:tensorflow:global_step/sec: 249.937\n",
      "INFO:tensorflow:loss = 1.0761478, step = 100 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.421\n",
      "INFO:tensorflow:loss = 1.051738, step = 200 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.681\n",
      "INFO:tensorflow:loss = 1.0272124, step = 300 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.204\n",
      "INFO:tensorflow:loss = 0.99163634, step = 400 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.458\n",
      "INFO:tensorflow:loss = 0.9623547, step = 500 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.509\n",
      "INFO:tensorflow:loss = 0.93421876, step = 600 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.507\n",
      "INFO:tensorflow:loss = 0.91090506, step = 700 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.727\n",
      "INFO:tensorflow:loss = 0.89766777, step = 800 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.642\n",
      "INFO:tensorflow:loss = 0.86850685, step = 900 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.198\n",
      "INFO:tensorflow:loss = 0.82641315, step = 1000 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.68\n",
      "INFO:tensorflow:loss = 0.8167921, step = 1100 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.36\n",
      "INFO:tensorflow:loss = 0.7994782, step = 1200 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.445\n",
      "INFO:tensorflow:loss = 0.7625321, step = 1300 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.205\n",
      "INFO:tensorflow:loss = 0.7491503, step = 1400 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.1\n",
      "INFO:tensorflow:loss = 0.7469481, step = 1500 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.039\n",
      "INFO:tensorflow:loss = 0.72723854, step = 1600 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.21\n",
      "INFO:tensorflow:loss = 0.72539216, step = 1700 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.678\n",
      "INFO:tensorflow:loss = 0.72240645, step = 1800 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.759\n",
      "INFO:tensorflow:loss = 0.6921108, step = 1900 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.807\n",
      "INFO:tensorflow:loss = 0.69624925, step = 2000 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.409\n",
      "INFO:tensorflow:loss = 0.68255746, step = 2100 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.569\n",
      "INFO:tensorflow:loss = 0.6913147, step = 2200 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.055\n",
      "INFO:tensorflow:loss = 0.66840816, step = 2300 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.236\n",
      "INFO:tensorflow:loss = 0.6635926, step = 2400 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.989\n",
      "INFO:tensorflow:loss = 0.6399421, step = 2500 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.737\n",
      "INFO:tensorflow:loss = 0.6606332, step = 2600 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.27\n",
      "INFO:tensorflow:loss = 0.63629955, step = 2700 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.988\n",
      "INFO:tensorflow:loss = 0.6218705, step = 2800 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.024\n",
      "INFO:tensorflow:loss = 0.63862056, step = 2900 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.508\n",
      "INFO:tensorflow:loss = 0.63278896, step = 3000 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.374\n",
      "INFO:tensorflow:loss = 0.62237316, step = 3100 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.292\n",
      "INFO:tensorflow:loss = 0.6178385, step = 3200 (0.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.61\n",
      "INFO:tensorflow:loss = 0.60361487, step = 3300 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.068\n",
      "INFO:tensorflow:loss = 0.61072725, step = 3400 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.268\n",
      "INFO:tensorflow:loss = 0.59731185, step = 3500 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.203\n",
      "INFO:tensorflow:loss = 0.6067846, step = 3600 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.176\n",
      "INFO:tensorflow:loss = 0.6133741, step = 3700 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.391\n",
      "INFO:tensorflow:loss = 0.5962271, step = 3800 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.89\n",
      "INFO:tensorflow:loss = 0.5938095, step = 3900 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 303.344\n",
      "INFO:tensorflow:loss = 0.5893512, step = 4000 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.729\n",
      "INFO:tensorflow:loss = 0.5959897, step = 4100 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.29\n",
      "INFO:tensorflow:loss = 0.57945025, step = 4200 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.173\n",
      "INFO:tensorflow:loss = 0.574952, step = 4300 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.364\n",
      "INFO:tensorflow:loss = 0.57061076, step = 4400 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.396\n",
      "INFO:tensorflow:loss = 0.56958336, step = 4500 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.821\n",
      "INFO:tensorflow:loss = 0.5619714, step = 4600 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.857\n",
      "INFO:tensorflow:loss = 0.5566001, step = 4700 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.479\n",
      "INFO:tensorflow:loss = 0.5485898, step = 4800 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.569\n",
      "INFO:tensorflow:loss = 0.5631816, step = 4900 (0.332 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into C:\\Users\\vamsee\\AppData\\Local\\Temp\\tmpywpck99t\\model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
      "INFO:tensorflow:Loss for final step: 0.543072.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x295fd3aca30>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(\n",
    "input_fn= lambda: input_func(X_train,Y_train), steps=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2022-02-04T11:33:50\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\vamsee\\AppData\\Local\\Temp\\tmpywpck99t\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.27816s\n",
      "INFO:tensorflow:Finished evaluation at 2022-02-04-11:33:51\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.7, average_loss = 0.65659344, global_step = 5000, loss = 0.65659344\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: C:\\Users\\vamsee\\AppData\\Local\\Temp\\tmpywpck99t\\model.ckpt-5000\n"
     ]
    }
   ],
   "source": [
    "### now evaluate the model as follows\n",
    "\n",
    "res= model.evaluate(input_fn=lambda: input_func(X_test,Y_test,False ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter SepalLength 1.1\n",
      "enter SepalWidth 2.2\n",
      "enter PetalLength 3.3\n",
      "enter PetalWidth 4.4\n"
     ]
    }
   ],
   "source": [
    "### lets build a predict model\n",
    "\n",
    "\n",
    "def input_fc(inputs):\n",
    "    res = tf.data.Dataset.from_tensor_slices(dict(inputs)).batch(256)\n",
    "    return res\n",
    "\n",
    "inputs={}\n",
    "for features in X_train.columns:\n",
    "    \n",
    "    flag=True\n",
    "    \n",
    "    while flag:\n",
    "        val=input(\"enter {}\".format(features))\n",
    "        \n",
    "        if not val.isdigit(): flag=False\n",
    "    inputs[features]= [float(val)]\n",
    "    \n",
    "res = model.predict(input_fn=lambda: input_fc(predict_x))\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in res:\n",
    "    print(i[\"class_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\vamsee\\AppData\\Local\\Temp\\tmpywpck99t\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "{'logits': array([ 2.3316545 , -0.63042676, -2.3094394 ], dtype=float32), 'probabilities': array([0.94218886, 0.04872169, 0.00908942], dtype=float32), 'class_ids': array([0], dtype=int64), 'classes': array([b'0'], dtype=object), 'all_class_ids': array([0, 1, 2]), 'all_classes': array([b'0', b'1', b'2'], dtype=object)}\n",
      "0\n",
      "Prediction is \"Setosa\" (94.2%)\n",
      "{'logits': array([-0.08633064,  0.2496356 ,  0.13372627], dtype=float32), 'probabilities': array([0.27431536, 0.38384724, 0.34183747], dtype=float32), 'class_ids': array([1], dtype=int64), 'classes': array([b'1'], dtype=object), 'all_class_ids': array([0, 1, 2]), 'all_classes': array([b'0', b'1', b'2'], dtype=object)}\n",
      "1\n",
      "Prediction is \"Versicolor\" (38.4%)\n",
      "{'logits': array([-0.55054015,  0.30188596,  0.6832057 ], dtype=float32), 'probabilities': array([0.1475057 , 0.34594956, 0.50654477], dtype=float32), 'class_ids': array([2], dtype=int64), 'classes': array([b'2'], dtype=object), 'all_class_ids': array([0, 1, 2]), 'all_classes': array([b'0', b'1', b'2'], dtype=object)}\n",
      "2\n",
      "Prediction is \"Virginica\" (50.7%)\n"
     ]
    }
   ],
   "source": [
    "for pred_dict in res:\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    print(pred_dict)\n",
    "    print(class_id)\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "    print('Prediction is \"{}\" ({:.1f}%)'.format(\n",
    "        SPECIES[class_id], 100 * probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Estimator.predict at 0x00000295FBBB79E0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
